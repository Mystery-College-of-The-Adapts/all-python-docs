{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last Updated: 7-29-2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Overview\" data-toc-modified-id=\"Overview-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview</a></div><div class=\"lev2 toc-item\"><a href=\"#Conventional-Approach:-Working-with-Unlabelled-Arrays\" data-toc-modified-id=\"Conventional-Approach:-Working-with-Unlabelled-Arrays-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Conventional Approach: Working with Unlabelled Arrays</a></div><div class=\"lev2 toc-item\"><a href=\"#Challenges\" data-toc-modified-id=\"Challenges-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Challenges</a></div><div class=\"lev2 toc-item\"><a href=\"#The-network-Common-Data-Format-(netCDF)\" data-toc-modified-id=\"The-network-Common-Data-Format-(netCDF)-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>The network Common Data Format (netCDF)</a></div><div class=\"lev2 toc-item\"><a href=\"#NetCDF-in-practice\" data-toc-modified-id=\"NetCDF-in-practice-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>NetCDF in practice</a></div><div class=\"lev2 toc-item\"><a href=\"#Handling-large-arrays\" data-toc-modified-id=\"Handling-large-arrays-15\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Handling large arrays</a></div><div class=\"lev2 toc-item\"><a href=\"#Key-Points\" data-toc-modified-id=\"Key-Points-16\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Key Points</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unlabelled, N-dimensional arrays of numbers, such as NumPy's ndarray, are the most widely used data structure in scientific computing.\n",
    "\n",
    "- Geoscientists have a particular need for structuring their data as arrays. For example we commonly work with sets of climate variables(e.g. temperature and precipitation) that vary in space and time and are represented on a regularly-spaced grid. Often we need to subset a large global grid to look at data for a particular region, or select a specific time slice. Then we might want to apply statistical functions to these subsetted groups to generate summary information.\n",
    "\n",
    "![](https://i.imgur.com/Jj5JINC.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conventional Approach: Working with Unlabelled Arrays\n",
    "\n",
    "Multidimensional array data are often stored in user-defined binary formats, and distributed with custom Fortran or C++ libraries used to read and process the data. Users are responsible for setting up their own file structures and custom codes to handle these files. Subsetting the data involves reading everything into an in-memory array, and then using a series of nested loops with conditional statements to look for a specific range of index values associated with the temporal or spatial slice needed. Also, clever use of matrix algebra is often used to summarize data across spatial and temporal dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The biggest challenge in working with N-dimensional arrays in convential approaches(working with unlabelled Arrays) is the fact that the data are almost dissociated from their metadata.\n",
    "\n",
    "- Users are left with the task of tracking the meaning behind array indices using domain specific tools, often leading to inefficiencies and errors.\n",
    "\n",
    "- Common pitfalls often occur in the form of questions like \"is the time axis of my array in the first or third index position?\", or \"does my array of timestamps still align with my data after resampling?\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The network Common Data Format (netCDF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The network Common Data Format, or netCDF, was created in the early 1990s, and set out to solve some of the challenges in working with N-dimensional arrays. \n",
    "- Netcdf is a collection of self-describing, machine-independent binary data formats and software tools that facilitate the creation, access and sharing of scientific data stored in N-dimensional arrays, along with metadata describing the contents of each array. \n",
    "- Netcdf was built by the climate science community at a time when regional climate models were beginning to produce larger and larger output files. \n",
    "- Another format, HDF5, has been used for many applications including distribution of remote sensing datasets. It turns out these two formats are now merging, such that the latest version netCDF-4 is the HDF5 format but with some restrictions.\n",
    "\n",
    "- One benefit of Common Data Formats is that they are structured in ways that enable rapid subsetting and analysis using simple command line tools. For example, the climate community has developed their own netCDF toolkits that accomplish tasks like subsetting and grouping. Similar tools exist for HDF5. Therefore many researchers utilize these tools exclusively in their analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NetCDF in practice\n",
    "NetCDF has been widely adopted as a standard format for distributing N-dimensional arrays. Although many geoscience communities rely entirely on existing NetCDF software tools for processing and visualizing their data, others simply use NetCDF as a convenient format for serializing their arrays. In many applications, existing NetCDF tools do not provide the flexibility needed for a specific research question, and users end up reading arrays into memory. They then perform statistical and subsetting operations using conventional coding methods (e.g. looping over array indices) described above.\n",
    "\n",
    "## Handling large arrays\n",
    "The NetCDF format has no limit on file sizes. However, any analysis tools that read data from a NetCDF array into memory for some computational operation will be limited by that particular machine’s available memory. As many multidimensional datasets grow in size, for example due to increases in model resolution and remote sensing capabilities, we are becoming increasingly limited in our ability to handle these large datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Points\n",
    "\n",
    "- unlabelled, N-dimensional arrays of numbers (e.g. NumPy’s ndarray) are the most widely used data structure in scientific computing\n",
    "- these arrays lack meaningful metadata, so users must track indices in an arbitrary fashion\n",
    "- in-memory operations, needed to process and visualize large arrays, are reaching limits as datasets grow in size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "153px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
